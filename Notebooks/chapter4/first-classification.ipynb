{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Classification - Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first.classification.algorithm <- function(training.set, test.set) {\n",
    "\t# Defining the column id that represents the expected class\n",
    "\tclassAttributeId = ncol(training.set)\n",
    "\n",
    "\t# Setting X and Y for training\n",
    "\ttraining.X = training.set[,1:(classAttributeId-1)]\n",
    "\ttraining.Y = training.set[,classAttributeId]\n",
    "\n",
    "\t# Setting X and Y for testing\n",
    "\ttest.X = test.set[,1:(classAttributeId-1)]\n",
    "\ttest.Y = test.set[,classAttributeId]\n",
    "\n",
    "\t# The final results are saved in this variable\n",
    "\tresults = NULL\n",
    "\n",
    "\tcat(\"# Outcome\\tExpected class\\n\")\n",
    "\t# For every unseen example in the test set\n",
    "\tfor (unseen in 1:nrow(test.X)) {\n",
    "\n",
    "\t\t# These variables count the number of positive and\n",
    "\t\t# negative examples in the training set\n",
    "\t\tm_positive = 0\n",
    "\t\tm_negative = 0\n",
    "\n",
    "\t\t# To sum up the dot product of the unseen example\n",
    "\t\t# against every other example contained in the positive\n",
    "\t\t# and the negative classes\n",
    "\t\tsum_positive = 0\n",
    "\t\tsum_negative = 0\n",
    "\n",
    "\t\t# Apply the equations for the unseen example test.X[unseen,]\n",
    "\t\t# given the training set\n",
    "\t\tfor (i in 1:nrow(training.X)) {\n",
    "\n",
    "\t\t\tif (training.Y[i] == +1) {\n",
    "\t\t\t\tsum_positive = sum_positive + test.X[unseen,] %*% training.X[i,]\n",
    "\t\t\t\tm_positive = m_positive + 1\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\tif (training.Y[i] == -1) {\n",
    "\t\t\t\tsum_negative = sum_negative + test.X[unseen,] %*% training.X[i,]\n",
    "\t\t\t\tm_negative = m_negative + 1\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\n",
    "\t\t# These variables store the squared number of positive and \n",
    "\t\t# negative examples in the training set. They are required\n",
    "\t        # to compute term b\n",
    "\t\tm_squared_positive = 0\n",
    "\t\tm_squared_negative = 0\n",
    "\n",
    "\t\t# To sum up the dot product of the unseen example\n",
    "\t\t# against every example contained in the positive\n",
    "\t\t# and the negative classes. They ares used to compute term b\n",
    "\t\tsum_b_positive = 0\n",
    "\t\tsum_b_negative = 0\n",
    "\n",
    "\t\t# Starting the computation of term b\n",
    "\t\tfor (i in 1:nrow(training.X)) {\n",
    "\t\t\tfor (j in 1:nrow(training.X)) {\n",
    "\n",
    "\t\t\t\tif (training.Y[i] == -1 && training.Y[j] == -1 ) {\n",
    "\t\t\t\t\tsum_b_negative = sum_b_negative + training.X[i,] %*% training.X[j,]\n",
    "\t\t\t\t\tm_squared_negative = m_squared_negative + 1\n",
    "\t\t\t\t}\n",
    "\n",
    "\t\t\t\tif (training.Y[i] == +1 && training.Y[j] == +1 ) {\n",
    "\t\t\t\t\tsum_b_positive = sum_b_positive + training.X[i,] %*% training.X[j,]\n",
    "\t\t\t\t\tm_squared_positive = m_squared_positive + 1\n",
    "\n",
    "\t\t\t\t}\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\n",
    "\t\t# Finally, we have term b.\n",
    "\t\t# We do not square variables m_squared_negative and m_squared_positive\n",
    "\t\t# because they were already squared due to the double loops used above\n",
    "\t\tb = 1/2 * (1/m_squared_negative * sum_b_negative - 1/m_squared_positive * sum_b_positive)\n",
    "\n",
    "\t\t# Now term y is computed to answer whether the unseen example will be\n",
    "\t\t# classified either as positive or negative\n",
    "\t\ty = sign(1/m_positive * sum_positive - 1/m_negative * sum_negative + b)\n",
    "\n",
    "\t\t# Saving the output class and the expected one, respectively\n",
    "\t\tresults = rbind(results, cbind(y, test.Y[unseen]))\n",
    "\n",
    "\t\t# Printing out the results\n",
    "\t\tcat(y, \"\", test.Y[unseen], \"\\n\")\n",
    "\t}\n",
    "\n",
    "\treturn (results)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.first <- function() {\n",
    "\n",
    "\t# Generating the positive examples\n",
    "\tdataset = cbind(rnorm(mean=0, sd=1, n=100), rnorm(mean=0, sd=1, n=100), rep(1, 100))\n",
    "\n",
    "\t# Generating the negative examples\n",
    "\tdataset = rbind(dataset, cbind(rnorm(mean=10, sd=1, n=100), rnorm(mean=10, sd=1, n=100), rep(-1, 100)))\n",
    "\n",
    "\t# Plotting the dataset\n",
    "\tplot(dataset[,1:2], col=dataset[,3]+2)\n",
    "\tcat(\"Click on the chart to continue...\\n\")\n",
    "\tlocator(1)\n",
    "\n",
    "\t# Setting the training set size\n",
    "\ttrain.size = round(nrow(dataset)/2)\n",
    "\n",
    "\t# Sampling half of this dataset for training\n",
    "\tid = sample(1:nrow(dataset), size=train.size)\n",
    "\n",
    "\t# Building up the training set\n",
    "\ttrain.set = dataset[id,]\n",
    "\n",
    "\t# Building up the test set\n",
    "\ttest.set = dataset[-id,]\n",
    "\n",
    "\t# Calling our classification algorithm to check the results\n",
    "\tresults = first.classification.algorithm(train.set, test.set)\n",
    "\n",
    "\treturn (results)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Classification - Complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.complex <- function() {\n",
    "\n",
    "\t# Generating the positive examples\n",
    "\tdataset = cbind(rnorm(mean=0, sd=0.25, n=200), rnorm(mean=0, sd=0.25, n=200), rep(1, 200))\n",
    "\n",
    "\t# Generating the negative examples\n",
    "\tnegative.set = 5*sin(2*pi*seq(0,9,len=200))+rnorm(mean=0, sd=0.5, n=200)\n",
    "\tdataset = rbind(dataset, cbind(negative.set[1:(length(negative.set)-5)], \n",
    "\t\t\t\tnegative.set[6:length(negative.set)], rep(-1, length(negative.set)-5)))\n",
    "\n",
    "\t# Plotting the dataset\n",
    "\tplot(dataset[,1:2], col=dataset[,3]+2)\n",
    "\tcat(\"Click on the chart to continue...\\n\")\n",
    "\tlocator(1)\n",
    "\n",
    "\t# Setting the training set size\n",
    "\ttrain.size = round(nrow(dataset)/2)\n",
    "\n",
    "\t# Sampling half of this dataset for training\n",
    "\tid = sample(1:nrow(dataset), size=train.size)\n",
    "\n",
    "\t# Building up the training set\n",
    "\ttrain.set = dataset[id,]\n",
    "\n",
    "\t# Building up the test set\n",
    "\ttest.set = dataset[-id,]\n",
    "\n",
    "\t# Calling our classification algorithm to check results\n",
    "\tresults = first.classification.algorithm(train.set, test.set)\n",
    "\n",
    "\treturn (results)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Classification - Second Complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "require(rgl)\n",
    "\n",
    "Transformation <- function(vec) {\n",
    "\tclass = vec[3]\n",
    "\t# Observe the expected class will be the same\n",
    "\treturn (c(vec[1]^2, sqrt(2)*vec[1]*vec[2], vec[2]^2, class))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.complex.kernel <- function() {\n",
    "\n",
    "\t# Generating the positive examples\n",
    "\tdataset = cbind(rnorm(mean=0, sd=0.25, n=200), rnorm(mean=0, sd=0.25, n=200), rep(1, 200))\n",
    "\n",
    "\t# Generating the negative examples\n",
    "\tnegative.set = 5*sin(2*pi*seq(0,9,len=200))+rnorm(mean=0, sd=0.5, n=200)\n",
    "\tdataset = rbind(dataset, cbind(negative.set[1:(length(negative.set)-5)], \n",
    "\t\t\t\tnegative.set[6:length(negative.set)], rep(-1, length(negative.set)-5)))\n",
    "\n",
    "\t# Plotting the original dataset\n",
    "\tplot(dataset[,1:2], col=dataset[,3]+2)\n",
    "\tcat(\"Click on the chart to continue...\\n\")\n",
    "\tlocator(1)\n",
    "\n",
    "\t# Applying the kernel function to map every example into the features space\n",
    "\tnew.dataset = NULL\n",
    "\tfor (i in 1:nrow(dataset)) {\n",
    "\t\tnew.dataset = rbind(new.dataset, Transformation(dataset[i,]))\n",
    "\t}\n",
    "\n",
    "\tprint(new.dataset)\n",
    "\t# Plotting the transformed dataset\n",
    "\tplot3d(new.dataset[,1:3], col=new.dataset[,4]+2)\n",
    "\n",
    "\t# Setting the training set size\n",
    "\ttrain.size = round(nrow(new.dataset)/2)\n",
    "\n",
    "\t# Sampling half of this new.dataset for training\n",
    "\tid = sample(1:nrow(new.dataset), size=train.size)\n",
    "\n",
    "\t# Building up the training set\n",
    "\ttrain.set = new.dataset[id,]\n",
    "\n",
    "\t# Building up the test set\n",
    "\ttest.set = new.dataset[-id,]\n",
    "\n",
    "\t# Calling our classification algorithm to check results\n",
    "\tresults = first.classification.algorithm(train.set, test.set)\n",
    "\n",
    "\treturn (results)\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
