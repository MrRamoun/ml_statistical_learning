{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heaviside function with a default epsilon\n",
    "g <- function(net, epsilon=0.5) {\n",
    "\tif (net > epsilon) {\n",
    "\t\treturn (1)\n",
    "\t} else {\n",
    "\t\treturn (0)\n",
    "\t}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the function to train the Perceptron\n",
    "# Observe eta and threshold assume default values\n",
    "perceptron.train <- function(train.table, eta=0.1, threshold=1e-2) {\n",
    "\n",
    "\t# Number of input variables\n",
    "\tnVars = ncol(train.table)-1\n",
    "\n",
    "\tcat(\"Randomizing weights and theta in range [-0.5, 0.5]...\\n\")\n",
    "\n",
    "\t# Randomizing weights\n",
    "\tweights = runif(min=-0.5, max=0.5, n=nVars)\n",
    "\n",
    "\t# Randomizing theta\n",
    "\ttheta = runif(min=-0.5, max=0.5, n=1)\n",
    "\n",
    "\t# This sum of squared errors will accumulate all errors\n",
    "\t# occuring along training iterations. When this error is\n",
    "\t# below a given threshold, learning stops.\n",
    "\tsumSquaredError = 2*threshold\n",
    "\n",
    "\t# Learning iterations\n",
    "\twhile (sumSquaredError > threshold) {\n",
    "\n",
    "\t\t# Initializing the sum of squared errors as zero\n",
    "\t\t# to start counting and later evaluate the total\n",
    "\t\t# loss for this dataset in train.table\n",
    "\t\tsumSquaredError = 0\n",
    "\n",
    "\t\t# Iterate along all rows (examples) contained in\n",
    "\t\t# train.table\n",
    "\t\tfor (i in 1:nrow(train.table)) {\n",
    "\n",
    "\t\t\t# Example x_i\n",
    "\t\t\tx_i = train.table[i, 1:nVars]\n",
    "\n",
    "\t\t\t# Expected output class\n",
    "\t\t\t# Observe the last column of this table\n",
    "\t\t\t# contains the output class\n",
    "\t\t\ty_i = train.table[i, ncol(train.table)]\n",
    "\n",
    "\t\t\t# Now the Perceptron produces the output\n",
    "\t\t\t# class using the current values for \n",
    "\t\t\t# weights and theta, then it applies the\n",
    "\t\t\t# heaviside function\n",
    "\t\t\that_y_i = g(x_i %*% weights + theta)\n",
    "\n",
    "\t\t\t# This is the error, referred to as (y_i - g(x_i))\n",
    "\t\t\t# in the Perceptron formulation\n",
    "\t\t\tError = y_i - hat_y_i\n",
    "\n",
    "\t\t\t# As part of the Gradient Descent method, we here\n",
    "\t\t\t# compute the partial derivative of the Squared Error\n",
    "\t\t\t# for the current example i in terms of weights and theta.\n",
    "\t\t\t# Observe constant 2 is not necessary, once we\n",
    "\t\t\t# can set eta using the value we desire\n",
    "\t\t\tdE2_dw1 = 2 * Error * -x_i\n",
    "\t\t\tdE2_dtheta = 2 * Error * -1\n",
    "\n",
    "\t\t\t# This is the Gradient Descent method to adapt\n",
    "\t\t\t# weights and theta as defined in the formulation\n",
    "\t\t\tweights = weights - eta * dE2_dw1\n",
    "\t\t\ttheta = theta - eta * dE2_dtheta\n",
    "\n",
    "\t\t\t# Accumulating the squared error to define the stop criterion\n",
    "\t\t\tsumSquaredError = sumSquaredError + Error^2\n",
    "\t\t}\n",
    "\n",
    "\t\tcat(\"Accumulated sum of squared errors = \", sumSquaredError, \"\\n\")\n",
    "\t}\n",
    "\n",
    "\t# Returning weights and theta, once they represent the solution\n",
    "\tret = list()\n",
    "\tret$weights = weights\n",
    "\tret$theta = theta\n",
    "\n",
    "\treturn (ret)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the function to execute the Perceptron\n",
    "# over unseen data (new examples)\n",
    "perceptron.test <- function(test.table, weights, theta) {\n",
    "\n",
    "\t# Here we print out the expected class (yi) followed by the\n",
    "\t# obtained one (hat_yi) when considering weights and theta.\n",
    "\t# Of course, function perceptron.train should be called\n",
    "\t# previously, in order to find the values for weights and theta\n",
    "\tcat(\"#yi\\that_yi\\n\")\n",
    "\n",
    "\t# Number of input variables\n",
    "\tnVars = ncol(test.table)-1\n",
    "\n",
    "\t# For every row in the test.table\n",
    "\tfor (i in 1:nrow(test.table)) {\n",
    "\n",
    "\t\t# Example i\n",
    "\t\tx_i = test.table[i, 1:nVars]\n",
    "\n",
    "\t\t# Expected class for example i\n",
    "\t\ty_i = test.table[i, ncol(test.table)]\n",
    "\n",
    "\t\t# Output class produced by the Perceptron\n",
    "\t\that_y_i = g(x_i %*% weights + theta)\n",
    "\n",
    "\t\tcat(y_i, \"\\t\", hat_y_i, \"\\n\")\n",
    "\t}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron.run.simple <- function() {\n",
    "\n",
    "\t# This is a table with training examples\n",
    "\ttrain.table = matrix(c(0.0, 0,\n",
    "\t\t\t       0.1, 0,\n",
    "\t\t\t       0.2, 0,\n",
    "\t\t\t       0.3, 0,\n",
    "\t\t\t       0.4, 0,\n",
    "\t\t\t       0.5, 0,\n",
    "\t\t\t       0.6, 1,\n",
    "\t\t\t       0.7, 1,\n",
    "\t\t\t       0.8, 1,\n",
    "\t\t\t       0.9, 1,\n",
    "\t\t\t       1.0, 1),\n",
    "\t\t\t      nrow=11,\n",
    "\t\t\t      ncol=2,\n",
    "\t\t\t      byrow=TRUE)\n",
    "\n",
    "\t# This is a table with test examples.\n",
    "\t# The last column only shows the expected\n",
    "\t# output and it is not used in the testing stage\n",
    "\ttest.table = matrix(c(0.05, 0,\n",
    "\t\t\t      0.15, 0,\n",
    "\t\t\t      0.25, 0,\n",
    "\t\t\t      0.35, 0,\n",
    "\t\t\t      0.45, 0,\n",
    "\t\t\t      0.55, 1,\n",
    "\t\t\t      0.65, 1,\n",
    "\t\t\t      0.75, 1,\n",
    "\t\t\t      0.85, 1,\n",
    "\t\t\t      0.95, 1),\n",
    "\t\t\t     nrow=10,\n",
    "\t\t\t     ncol=2,\n",
    "\t\t\t     byrow=TRUE)\n",
    "\n",
    "\t# Training the Perceptron to find weights and theta\n",
    "\ttraining.result = perceptron.train(train.table)\n",
    "\n",
    "\t# Testing the Perceptron with the weights and theta found\n",
    "\tperceptron.test(test.table, training.result$weights, training.result$theta)\n",
    "\n",
    "\treturn (training.result)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomizing weights and theta in range [-0.5, 0.5]...\n",
      "Accumulated sum of squared errors =  2 \n",
      "Accumulated sum of squared errors =  1 \n",
      "Accumulated sum of squared errors =  2 \n",
      "Accumulated sum of squared errors =  1 \n",
      "Accumulated sum of squared errors =  0 \n",
      "#yi\that_yi\n",
      "0 \t 0 \n",
      "0 \t 0 \n",
      "0 \t 0 \n",
      "0 \t 0 \n",
      "0 \t 0 \n",
      "1 \t 1 \n",
      "1 \t 1 \n",
      "1 \t 1 \n",
      "1 \t 1 \n",
      "1 \t 1 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$weights</dt>\n",
       "\t\t<dd>0.491558475960046</dd>\n",
       "\t<dt>$theta</dt>\n",
       "\t\t<dd>0.236463076760992</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$weights] 0.491558475960046\n",
       "\\item[\\$theta] 0.236463076760992\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$weights\n",
       ":   0.491558475960046\n",
       "$theta\n",
       ":   0.236463076760992\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$weights\n",
       "[1] 0.4915585\n",
       "\n",
       "$theta\n",
       "[1] 0.2364631\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perceptron.run.simple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function plots the hyperplane found for this simplest\n",
    "# problem which considers a single input variable.\n",
    "# Variables range.start and range.end define the interval of\n",
    "# values for the single input variable composing the problem.\n",
    "# This simple problem has a single variable composing every\n",
    "# example i, which is x_i,1\n",
    "perceptron.simple.hyperplane.plot <- function(weight, theta, range.start=0, range.end=1) {\n",
    "\n",
    "\t# Number of variables is 1\n",
    "\tnVars = 1\n",
    "\n",
    "\t# We will now define the same range for the input variable.\n",
    "\t# This range will contain 100 discretized values\n",
    "\trange_of_every_input_variable = seq(range.start, range.end, length=100)\n",
    "\tx_1 = range_of_every_input_variable\n",
    "\t\n",
    "\t# Computing net for every input value of variable x_i,1\n",
    "\tall_nets = cbind(x_1, 1) %*% c(weight, theta)\n",
    "\n",
    "\t# This variable all_nets contains all net values for all values assumed\n",
    "\t# by variable x_1. Variable hat_y will contain the Perceptron outputs after\n",
    "\t# applying the heaviside function\n",
    "\that_y = rep(0, length(all_nets))\n",
    "\tfor (i in 1:length(all_nets)) {\n",
    "\t\that_y[i] = g(all_nets[i])\n",
    "\t}\n",
    "\n",
    "\t# Variable hyperplane will contain two columns, the first corresponds to\n",
    "\t# the input value of x_i,1 and the second to the class produced by the\n",
    "\t# Perceptron\n",
    "\thyperplane = cbind(x_1, hat_y)\n",
    "\n",
    "\t# Plotting the hyperplane found by the Perceptron\n",
    "\tplot(hyperplane)\n",
    "   \n",
    "   plot(x_1, hat_y, cex.axis=1.25, cex=1.3, xlab=\"input x_1\", ylab=\"output hat_y (classes) and hyperplane (w,theta)\", cex.lab=1.25, yaxt=\"n\", ylim=c(-0.1,1.1))\n",
    "   lines(hyperplane, lwd=2.3, col=\"gray40\",lty=2)\n",
    "   axis(2, at=c(0,1), labels=c(0,1), cex.axis=1.25,cex.lab=1.25)\n",
    "\n",
    "\treturn (hyperplane)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>x_1</th><th scope=col>hat_y</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.00000000</td><td>0         </td></tr>\n",
       "\t<tr><td>0.01010101</td><td>0         </td></tr>\n",
       "\t<tr><td>0.02020202</td><td>0         </td></tr>\n",
       "\t<tr><td>0.03030303</td><td>0         </td></tr>\n",
       "\t<tr><td>0.04040404</td><td>0         </td></tr>\n",
       "\t<tr><td>0.05050505</td><td>0         </td></tr>\n",
       "\t<tr><td>0.06060606</td><td>0         </td></tr>\n",
       "\t<tr><td>0.07070707</td><td>0         </td></tr>\n",
       "\t<tr><td>0.08080808</td><td>0         </td></tr>\n",
       "\t<tr><td>0.09090909</td><td>0         </td></tr>\n",
       "\t<tr><td>0.10101010</td><td>0         </td></tr>\n",
       "\t<tr><td>0.11111111</td><td>0         </td></tr>\n",
       "\t<tr><td>0.12121212</td><td>0         </td></tr>\n",
       "\t<tr><td>0.13131313</td><td>0         </td></tr>\n",
       "\t<tr><td>0.14141414</td><td>0         </td></tr>\n",
       "\t<tr><td>0.15151515</td><td>0         </td></tr>\n",
       "\t<tr><td>0.16161616</td><td>0         </td></tr>\n",
       "\t<tr><td>0.17171717</td><td>0         </td></tr>\n",
       "\t<tr><td>0.18181818</td><td>0         </td></tr>\n",
       "\t<tr><td>0.19191919</td><td>0         </td></tr>\n",
       "\t<tr><td>0.20202020</td><td>0         </td></tr>\n",
       "\t<tr><td>0.21212121</td><td>0         </td></tr>\n",
       "\t<tr><td>0.22222222</td><td>0         </td></tr>\n",
       "\t<tr><td>0.23232323</td><td>0         </td></tr>\n",
       "\t<tr><td>0.24242424</td><td>0         </td></tr>\n",
       "\t<tr><td>0.25252525</td><td>0         </td></tr>\n",
       "\t<tr><td>0.26262626</td><td>0         </td></tr>\n",
       "\t<tr><td>0.27272727</td><td>0         </td></tr>\n",
       "\t<tr><td>0.28282828</td><td>0         </td></tr>\n",
       "\t<tr><td>0.29292929</td><td>0         </td></tr>\n",
       "\t<tr><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><td>0.7070707</td><td>1        </td></tr>\n",
       "\t<tr><td>0.7171717</td><td>1        </td></tr>\n",
       "\t<tr><td>0.7272727</td><td>1        </td></tr>\n",
       "\t<tr><td>0.7373737</td><td>1        </td></tr>\n",
       "\t<tr><td>0.7474747</td><td>1        </td></tr>\n",
       "\t<tr><td>0.7575758</td><td>1        </td></tr>\n",
       "\t<tr><td>0.7676768</td><td>1        </td></tr>\n",
       "\t<tr><td>0.7777778</td><td>1        </td></tr>\n",
       "\t<tr><td>0.7878788</td><td>1        </td></tr>\n",
       "\t<tr><td>0.7979798</td><td>1        </td></tr>\n",
       "\t<tr><td>0.8080808</td><td>1        </td></tr>\n",
       "\t<tr><td>0.8181818</td><td>1        </td></tr>\n",
       "\t<tr><td>0.8282828</td><td>1        </td></tr>\n",
       "\t<tr><td>0.8383838</td><td>1        </td></tr>\n",
       "\t<tr><td>0.8484848</td><td>1        </td></tr>\n",
       "\t<tr><td>0.8585859</td><td>1        </td></tr>\n",
       "\t<tr><td>0.8686869</td><td>1        </td></tr>\n",
       "\t<tr><td>0.8787879</td><td>1        </td></tr>\n",
       "\t<tr><td>0.8888889</td><td>1        </td></tr>\n",
       "\t<tr><td>0.8989899</td><td>1        </td></tr>\n",
       "\t<tr><td>0.9090909</td><td>1        </td></tr>\n",
       "\t<tr><td>0.9191919</td><td>1        </td></tr>\n",
       "\t<tr><td>0.9292929</td><td>1        </td></tr>\n",
       "\t<tr><td>0.9393939</td><td>1        </td></tr>\n",
       "\t<tr><td>0.9494949</td><td>1        </td></tr>\n",
       "\t<tr><td>0.9595960</td><td>1        </td></tr>\n",
       "\t<tr><td>0.9696970</td><td>1        </td></tr>\n",
       "\t<tr><td>0.9797980</td><td>1        </td></tr>\n",
       "\t<tr><td>0.9898990</td><td>1        </td></tr>\n",
       "\t<tr><td>1.0000000</td><td>1        </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{ll}\n",
       " x\\_1 & hat\\_y\\\\\n",
       "\\hline\n",
       "\t 0.00000000 & 0         \\\\\n",
       "\t 0.01010101 & 0         \\\\\n",
       "\t 0.02020202 & 0         \\\\\n",
       "\t 0.03030303 & 0         \\\\\n",
       "\t 0.04040404 & 0         \\\\\n",
       "\t 0.05050505 & 0         \\\\\n",
       "\t 0.06060606 & 0         \\\\\n",
       "\t 0.07070707 & 0         \\\\\n",
       "\t 0.08080808 & 0         \\\\\n",
       "\t 0.09090909 & 0         \\\\\n",
       "\t 0.10101010 & 0         \\\\\n",
       "\t 0.11111111 & 0         \\\\\n",
       "\t 0.12121212 & 0         \\\\\n",
       "\t 0.13131313 & 0         \\\\\n",
       "\t 0.14141414 & 0         \\\\\n",
       "\t 0.15151515 & 0         \\\\\n",
       "\t 0.16161616 & 0         \\\\\n",
       "\t 0.17171717 & 0         \\\\\n",
       "\t 0.18181818 & 0         \\\\\n",
       "\t 0.19191919 & 0         \\\\\n",
       "\t 0.20202020 & 0         \\\\\n",
       "\t 0.21212121 & 0         \\\\\n",
       "\t 0.22222222 & 0         \\\\\n",
       "\t 0.23232323 & 0         \\\\\n",
       "\t 0.24242424 & 0         \\\\\n",
       "\t 0.25252525 & 0         \\\\\n",
       "\t 0.26262626 & 0         \\\\\n",
       "\t 0.27272727 & 0         \\\\\n",
       "\t 0.28282828 & 0         \\\\\n",
       "\t 0.29292929 & 0         \\\\\n",
       "\t ⋮ & ⋮\\\\\n",
       "\t 0.7070707 & 1        \\\\\n",
       "\t 0.7171717 & 1        \\\\\n",
       "\t 0.7272727 & 1        \\\\\n",
       "\t 0.7373737 & 1        \\\\\n",
       "\t 0.7474747 & 1        \\\\\n",
       "\t 0.7575758 & 1        \\\\\n",
       "\t 0.7676768 & 1        \\\\\n",
       "\t 0.7777778 & 1        \\\\\n",
       "\t 0.7878788 & 1        \\\\\n",
       "\t 0.7979798 & 1        \\\\\n",
       "\t 0.8080808 & 1        \\\\\n",
       "\t 0.8181818 & 1        \\\\\n",
       "\t 0.8282828 & 1        \\\\\n",
       "\t 0.8383838 & 1        \\\\\n",
       "\t 0.8484848 & 1        \\\\\n",
       "\t 0.8585859 & 1        \\\\\n",
       "\t 0.8686869 & 1        \\\\\n",
       "\t 0.8787879 & 1        \\\\\n",
       "\t 0.8888889 & 1        \\\\\n",
       "\t 0.8989899 & 1        \\\\\n",
       "\t 0.9090909 & 1        \\\\\n",
       "\t 0.9191919 & 1        \\\\\n",
       "\t 0.9292929 & 1        \\\\\n",
       "\t 0.9393939 & 1        \\\\\n",
       "\t 0.9494949 & 1        \\\\\n",
       "\t 0.9595960 & 1        \\\\\n",
       "\t 0.9696970 & 1        \\\\\n",
       "\t 0.9797980 & 1        \\\\\n",
       "\t 0.9898990 & 1        \\\\\n",
       "\t 1.0000000 & 1        \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "x_1 | hat_y | \n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 0.00000000 | 0          | \n",
       "| 0.01010101 | 0          | \n",
       "| 0.02020202 | 0          | \n",
       "| 0.03030303 | 0          | \n",
       "| 0.04040404 | 0          | \n",
       "| 0.05050505 | 0          | \n",
       "| 0.06060606 | 0          | \n",
       "| 0.07070707 | 0          | \n",
       "| 0.08080808 | 0          | \n",
       "| 0.09090909 | 0          | \n",
       "| 0.10101010 | 0          | \n",
       "| 0.11111111 | 0          | \n",
       "| 0.12121212 | 0          | \n",
       "| 0.13131313 | 0          | \n",
       "| 0.14141414 | 0          | \n",
       "| 0.15151515 | 0          | \n",
       "| 0.16161616 | 0          | \n",
       "| 0.17171717 | 0          | \n",
       "| 0.18181818 | 0          | \n",
       "| 0.19191919 | 0          | \n",
       "| 0.20202020 | 0          | \n",
       "| 0.21212121 | 0          | \n",
       "| 0.22222222 | 0          | \n",
       "| 0.23232323 | 0          | \n",
       "| 0.24242424 | 0          | \n",
       "| 0.25252525 | 0          | \n",
       "| 0.26262626 | 0          | \n",
       "| 0.27272727 | 0          | \n",
       "| 0.28282828 | 0          | \n",
       "| 0.29292929 | 0          | \n",
       "| ⋮ | ⋮ | \n",
       "| 0.7070707 | 1         | \n",
       "| 0.7171717 | 1         | \n",
       "| 0.7272727 | 1         | \n",
       "| 0.7373737 | 1         | \n",
       "| 0.7474747 | 1         | \n",
       "| 0.7575758 | 1         | \n",
       "| 0.7676768 | 1         | \n",
       "| 0.7777778 | 1         | \n",
       "| 0.7878788 | 1         | \n",
       "| 0.7979798 | 1         | \n",
       "| 0.8080808 | 1         | \n",
       "| 0.8181818 | 1         | \n",
       "| 0.8282828 | 1         | \n",
       "| 0.8383838 | 1         | \n",
       "| 0.8484848 | 1         | \n",
       "| 0.8585859 | 1         | \n",
       "| 0.8686869 | 1         | \n",
       "| 0.8787879 | 1         | \n",
       "| 0.8888889 | 1         | \n",
       "| 0.8989899 | 1         | \n",
       "| 0.9090909 | 1         | \n",
       "| 0.9191919 | 1         | \n",
       "| 0.9292929 | 1         | \n",
       "| 0.9393939 | 1         | \n",
       "| 0.9494949 | 1         | \n",
       "| 0.9595960 | 1         | \n",
       "| 0.9696970 | 1         | \n",
       "| 0.9797980 | 1         | \n",
       "| 0.9898990 | 1         | \n",
       "| 1.0000000 | 1         | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "      x_1        hat_y\n",
       " [1,] 0.00000000 0    \n",
       " [2,] 0.01010101 0    \n",
       " [3,] 0.02020202 0    \n",
       " [4,] 0.03030303 0    \n",
       " [5,] 0.04040404 0    \n",
       " [6,] 0.05050505 0    \n",
       " [7,] 0.06060606 0    \n",
       " [8,] 0.07070707 0    \n",
       " [9,] 0.08080808 0    \n",
       "[10,] 0.09090909 0    \n",
       "[11,] 0.10101010 0    \n",
       "[12,] 0.11111111 0    \n",
       "[13,] 0.12121212 0    \n",
       "[14,] 0.13131313 0    \n",
       "[15,] 0.14141414 0    \n",
       "[16,] 0.15151515 0    \n",
       "[17,] 0.16161616 0    \n",
       "[18,] 0.17171717 0    \n",
       "[19,] 0.18181818 0    \n",
       "[20,] 0.19191919 0    \n",
       "[21,] 0.20202020 0    \n",
       "[22,] 0.21212121 0    \n",
       "[23,] 0.22222222 0    \n",
       "[24,] 0.23232323 0    \n",
       "[25,] 0.24242424 0    \n",
       "[26,] 0.25252525 0    \n",
       "[27,] 0.26262626 0    \n",
       "[28,] 0.27272727 0    \n",
       "[29,] 0.28282828 0    \n",
       "[30,] 0.29292929 0    \n",
       "[31,] ⋮          ⋮    \n",
       "[32,] 0.7070707  1    \n",
       "[33,] 0.7171717  1    \n",
       "[34,] 0.7272727  1    \n",
       "[35,] 0.7373737  1    \n",
       "[36,] 0.7474747  1    \n",
       "[37,] 0.7575758  1    \n",
       "[38,] 0.7676768  1    \n",
       "[39,] 0.7777778  1    \n",
       "[40,] 0.7878788  1    \n",
       "[41,] 0.7979798  1    \n",
       "[42,] 0.8080808  1    \n",
       "[43,] 0.8181818  1    \n",
       "[44,] 0.8282828  1    \n",
       "[45,] 0.8383838  1    \n",
       "[46,] 0.8484848  1    \n",
       "[47,] 0.8585859  1    \n",
       "[48,] 0.8686869  1    \n",
       "[49,] 0.8787879  1    \n",
       "[50,] 0.8888889  1    \n",
       "[51,] 0.8989899  1    \n",
       "[52,] 0.9090909  1    \n",
       "[53,] 0.9191919  1    \n",
       "[54,] 0.9292929  1    \n",
       "[55,] 0.9393939  1    \n",
       "[56,] 0.9494949  1    \n",
       "[57,] 0.9595960  1    \n",
       "[58,] 0.9696970  1    \n",
       "[59,] 0.9797980  1    \n",
       "[60,] 0.9898990  1    \n",
       "[61,] 1.0000000  1    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAADAFBMVEUAAAABAQECAgIDAwME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\nCCAkQAAhAQIICRDwfwcbWehVeMMCAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perceptron.simple.hyperplane.plot(0.491558475960046, 0.236463076760992)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
