{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple SVM - LowRankQP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook requires LowRankQP library to be runned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(\"LowRankQP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "require(LowRankQP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the main function which is responsible for solving the optimization problem using linear or a kth-order polynomial kernel. It receives the training set X and its corresponding classes Y in {-1, +1}. We also set the upper limit C for every value contained in vector alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.polynomial <- function(X, Y, C = Inf, polynomial.order = 2, threshold = 1e-8) {\n",
    "\n",
    "\t# Building up matrix Q. Observe the kernel function is defined\n",
    "\t# in here. If polynomial.order=1, then we are considering the\n",
    "\t# original input space of examples in X, otherwise we are applying\n",
    "\t# some nolinear space transformation.\n",
    "\tQmat <- (Y %*% t(Y)) * (1+(X %*% t(X)))^polynomial.order\n",
    "\n",
    "\t# Defining d as a vector containing values equal to -1\n",
    "\t# to ensure the problem solved by LowRankQP is the same as ours\n",
    "\tdvec <- rep(-1, nrow(X))\n",
    "\n",
    "\t# Defining matrix A as the transpose of vector y\n",
    "\tAmat <- t(Y)\n",
    "\n",
    "\t# Defining b as a zero vector\n",
    "\tbvec <- 0\n",
    "\n",
    "\t# Setting the upper limit vector with values defined by C\n",
    "\tuvec <- rep(C, nrow(X))\n",
    "\n",
    "\t# Running the LowRankQP function to find vector alpha for which\n",
    "\t# constraints are satisfied. Thus, we minimize the functional \n",
    "\t# defined by LowRankQP\n",
    "\tres <- LowRankQP(Qmat, dvec, Amat, bvec, uvec, method=\"CHOL\")\n",
    "\n",
    "\t# This is vector alpha found after the optimization process\n",
    "\talphas <- res$alpha\n",
    "\n",
    "\t# Here we define which are the support vectors using the values \n",
    "\t# in vector alpha. Values above some threshold are taken as more \n",
    "\t# relevant (remember these are the KKT multipliers) to define \n",
    "\t# constraints\n",
    "\tsupport.vectors <- which(alphas > threshold)\n",
    "\n",
    "\t# Finally, we define the identifiers of support vectors so we\n",
    "\t# know who they are\n",
    "\tsupport.alphas <- alphas[support.vectors]\n",
    "\n",
    "\t# Now we define the margin using the support vectors\n",
    "\tmargin <- support.vectors\n",
    "\n",
    "\t# and then compute the value for b\n",
    "\tb <- Y[margin] - t(support.alphas*Y[support.vectors]) %*% (1+(X[support.vectors,] %*% t(X[margin,])))^polynomial.order\n",
    "\n",
    "\t# Returning the whole model found during the optimization process\n",
    "\treturn (list(X=X, Y=Y, polynomial.order=polynomial.order, support.vectors=support.vectors, support.alphas=support.alphas, b=mean(b), all.alphas=as.vector(alphas)))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a simple function to provide the discrete classification for unseen examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete.classification <- function(model, testSet) {\n",
    "\n",
    "\t# Creating a vector to store labels\n",
    "\tall.labels = c()\n",
    "\n",
    "\t# For every unseen example in this test set\n",
    "\tfor (i in 1:nrow(testSet)) {\n",
    "\n",
    "\t\t# Use the model found through function svm.polynomial to\n",
    "\t\t# obtain the classification output\n",
    "\t\tlabel = sum(model$all.alphas * model$Y * (1+(testSet[i,] %*% t(model$X)))^model$polynomial.order) + model$b\n",
    "\n",
    "\t\t# If label >= 0, so the test example lies on the positive side \n",
    "\t\t# of the hyperplane, otherwise it lies on the negative one\n",
    "\t\tif (label >= 0) \n",
    "\t\t\tlabel = 1\n",
    "\t\telse\n",
    "\t\t\tlabel = -1\n",
    "\n",
    "\t\t# Storing labels\n",
    "\t\tall.labels = c(all.labels, label)\n",
    "\t}\n",
    "\n",
    "\t# Returning the labels found\n",
    "\treturn (all.labels)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a simple function to provide the continuous classification for unseen examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous.classification <- function(model, testSet) {\n",
    "\n",
    "\t# Creating a vector to store labels\n",
    "\tall.labels = c()\n",
    "\n",
    "\t# For every unseen example in this test set\n",
    "\tfor (i in 1:nrow(testSet)) {\n",
    "\n",
    "\t\t# Use the model found through function svm.polynomial to\n",
    "\t\t# obtain the classification output\n",
    "\t\tlabel = sum(model$all.alphas * model$Y * (1+(testSet[i,] %*% t(model$X)))^model$polynomial.order) + model$b\n",
    "\n",
    "\t\t# Storing labels\n",
    "\t\t# The signal associated with this value indicates the label, i.e., - corresponds \n",
    "\t\t# to class -1 and + to class +1. In addition, the magnitude of this variable\n",
    "\t\t# `label' informs us how close or far the unseen example is from the hyperplane\n",
    "\t\tall.labels = c(all.labels, label)\n",
    "\t}\n",
    "\n",
    "\t# Returning the labels found\n",
    "\treturn (all.labels)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a simple function to plot the hyperplane found, but only for bidimensional training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotHyperplane <- function(model, x.axis=c(-1,1), y.axis=c(-1,1), resolution=100, continuous=TRUE) {\n",
    "\n",
    "\t# Producing a set of values for the two dimensions of the training/test sets\n",
    "\tx = seq(x.axis[1], x.axis[2], len=resolution)\n",
    "\ty = seq(y.axis[1], y.axis[2], len=resolution)\n",
    "\n",
    "\t# This is a matrix to store what we refer to plot set.\n",
    "\t# It is bidimensional as the training and test sets\n",
    "\tplotSet = NULL\n",
    "\tfor (i in 1:length(x)) {\n",
    "\t\tfor (j in 1:length(y)) {\n",
    "\t\t\tplotSet = rbind(plotSet, c(x[i], y[j]))\n",
    "\t\t}\n",
    "\t}\n",
    "\n",
    "\t# This is a matrix to save labels for plotting\n",
    "\tlabels = NULL\n",
    "\tif (continuous) {\n",
    "\t\t# Running the continuous classification\n",
    "\t\tlabels = matrix(continuous.classification(model, plotSet), nrow=length(x), ncol=length(y), byrow=T)\n",
    "\t} else {\n",
    "\t\t# or the discrete classification\n",
    "\t\tlabels = matrix(discrete.classification(model, plotSet), nrow=length(x), ncol=length(y), byrow=T)\n",
    "\t}\n",
    "\n",
    "\t# Plotting the hyperplane found\n",
    "\tfilled.contour(x,y,labels)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function produces very simple linearly separable training/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simpleDataset <- function() {\n",
    "\n",
    "\t# Building up the training set with 100 examples\n",
    "\ttrain <- cbind(rnorm(mean=0, sd=1, n=100), rnorm(mean=0, sd=1, n=100))\n",
    "\ttrain <- rbind(train, cbind(rnorm(mean=10, sd=1, n=100), rnorm(mean=10, sd=1, n=100)))\n",
    "\ttrain <- cbind(train, c(rep(-1, 100), rep(1, 100)))\n",
    "\n",
    "\t# Building up the test set with 10 examples\n",
    "\ttest <- cbind(rnorm(mean=0, sd=1, n=10), rnorm(mean=0, sd=1, n=10))\n",
    "\ttest <- rbind(test, cbind(rnorm(mean=10, sd=1, n=10), rnorm(mean=10, sd=1, n=10)))\n",
    "\ttest <- cbind(test, c(rep(-1, 10), rep(1, 10)))\n",
    "\n",
    "\t# Returning both sets\n",
    "\treturn (list(train=train, test=test))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a very simple function to test function svm.polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSimpleDataset <- function() {\n",
    "\n",
    "\t# Building up a very simple linearly separable training set\n",
    "\tdataset = simpleDataset()\n",
    "\n",
    "\t# Optimizing values for alpha, given this simple dataset\n",
    "\tmodel = svm.polynomial(dataset$train[,1:2], dataset$train[,3], C=10000, polynomial.order=1)\n",
    "\n",
    "\t# Plotting all values in vector alpha to check them out\n",
    "\t# and observe which are the most relevant ones\n",
    "\tplot(model$all.alphas)\n",
    "\tlocator(1)\n",
    "\n",
    "\t# Plotting data space in black and support vectors in red\n",
    "\tplot(dataset$train[,1:2])\n",
    "\tpoints(dataset$train[model$support.vectors,1:2], col=2)\n",
    "\tlocator(1)\n",
    "\n",
    "\t# Printing labels -1 and +1 for verification\n",
    "\tlabels = discrete.classification(model, dataset$test[,1:2])\n",
    "\tresult = cbind(dataset$test[,3], labels)\n",
    "\tcolnames(result) = c(\"Expected class\", \"Obtained class\")\n",
    "\tcat(\"Discrete classification:\\n\")\n",
    "\tprint(result)\n",
    "\n",
    "\t# Printing the continuous classification out\n",
    "\tlabels = continuous.classification(model, dataset$test[,1:2])\n",
    "\tresult = cbind(dataset$test[,3], labels)\n",
    "\tcolnames(result) = c(\"Expected class\", \"Obtained class\")\n",
    "\tcat(\"Continuous classification:\\n\")\n",
    "\tprint(result)\n",
    "\n",
    "\t# Plotting the hiperplane found\n",
    "\tplotHyperplane(model, x.axis=c(-1,11), y.axis=c(-1,11), resolution=100, continuous=FALSE)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSimpleDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial SVM - LowRankQP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This package requires tseriesChaos package. To install it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(\"tseriesChaos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This package is used to build up the radial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "require(tseriesChaos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function builds up a radial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radialDataset <- function() {\n",
    "\t\n",
    "\t# Building up the training set with 1000 examples\n",
    "\ttrain <- rbind(cbind(rnorm(mean=0, sd=0.1, n=1000), rnorm(mean=0, sd=0.1, n=1000)))\n",
    "\ttrain <- rbind(train, embedd(2*sin(2*pi*seq(0,9,length=1027))+\n",
    "\t\t\t\t     rnorm(mean=0, sd=0.1, n=1027), m=2, d=27))\n",
    "\ttrain <- cbind(train, c(rep(-1, 1000), rep(+1, 1000)))\n",
    "\n",
    "\t# Building up the test set with 10 examples\n",
    "\ttest <- rbind(cbind(rnorm(mean=0, sd=0.1, n=10), rnorm(mean=0, sd=0.1, n=10)))\n",
    "\ttest <- rbind(test, embedd(2*sin(2*pi*seq(0,9,length=37))+\n",
    "\t\t\t\t   rnorm(mean=0, sd=0.1, n=37), m=2, d=27))\n",
    "\ttest <- cbind(test, c(rep(-1, 10), rep(+1, 10)))\n",
    "\n",
    "\treturn (list(train=train, test=test))\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function is used to test the SVM optimization with a radial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testRadialDataset <- function(C=10) {\n",
    "\n",
    "\t# Building up the radial dataset\n",
    "\tdataset = radialDataset()\n",
    "\n",
    "\t# Running the SVM optimizer, so we can estimate adequate values for vector alpha.\n",
    "\t# Notice we are now using a second-order polynomial kernel.\n",
    "\tmodel = svm.polynomial(dataset$train[,1:2], dataset$train[,3], C=C, \n",
    "\t\t\t       polynomial.order=2, threshold = 1e-3)\n",
    "\n",
    "\t# Plotting all values contained in vector alpha in order to check them out\n",
    "\t# and conclude on which are the most relevant ones\n",
    "\tplot(model$all.alphas)\n",
    "\tlocator(1)\n",
    "\n",
    "\t# Plotting the data space in black and support vectors in red\n",
    "\tplot(dataset$train[,1:2])\n",
    "\tpoints(dataset$train[model$support.vectors,1:2], col=2)\n",
    "\tlocator(1)\n",
    "\n",
    "\t# Printing labels -1 and +1 for verification\n",
    "\tlabels = discrete.classification(model, dataset$test[,1:2])\n",
    "\tresult = cbind(dataset$test[,3], labels)\n",
    "\tcolnames(result) = c(\"Expected class\", \"Obtained class\")\n",
    "\tcat(\"Discrete classification:\\n\")\n",
    "\tprint(result)\n",
    "\n",
    "\t# Printing the continuous classification out\n",
    "\tlabels = continuous.classification(model, dataset$test[,1:2])\n",
    "\tresult = cbind(dataset$test[,3], labels)\n",
    "\tcolnames(result) = c(\"Expected class\", \"Obtained class\")\n",
    "\tcat(\"Continuous classification:\\n\")\n",
    "\tprint(result)\n",
    "\n",
    "\t# Plotting the hiperplane found\n",
    "\tplotHyperplane(model, x.axis=c(-5,5), y.axis=c(-5,5), resolution=100, continuous=FALSE)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testRadialDataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
