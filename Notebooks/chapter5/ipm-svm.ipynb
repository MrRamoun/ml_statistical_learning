{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interior Point Method (IPM) SVM (Support Vector Machine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function builds up a very simple linearly separable dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Producing a two-dimensional dataset using the Normal distribution. Negative examples are defined to have mean (0,0) with standard deviation (1,1). Positive examples are defined to have mean (10,10) with standard deviation (1,1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simpleDataset <- function() {\n",
    "\n",
    "\t# These are the training examples\n",
    "\ttrain <- cbind(rnorm(mean=0, sd=1, n=100), rnorm(mean=0, sd=1, n=100))\n",
    "\ttrain <- rbind(train, cbind(rnorm(mean=10, sd=1, n=100), rnorm(mean=10, sd=1, n=100)))\n",
    "\ttrain <- cbind(train, c(rep(-1, 100), rep(1, 100)))\n",
    "\n",
    "\t# These are the test examples\n",
    "\ttest <- cbind(rnorm(mean=0, sd=1, n=10), rnorm(mean=0, sd=1, n=10))\n",
    "\ttest <- rbind(test, cbind(rnorm(mean=10, sd=1, n=10), rnorm(mean=10, sd=1, n=10)))\n",
    "\ttest <- cbind(test, c(rep(-1, 10), rep(1, 10)))\n",
    "\n",
    "\t# Returning the training and test sets using a list\n",
    "\treturn (list(train=train, test=test))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function outputs the classification (labels) for a given set. In our case, we use it to print out the labels predicted for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete.classification <- function(X, Y, alpha, b, X.test, Y.test, threshold = 1e-5) {\n",
    "\tall.labels = NULL\n",
    "\talphas = diag(alpha)\n",
    "\talphas[alphas < threshold] = 0\n",
    "\n",
    "\tfor (i in 1:nrow(X.test)) {\n",
    "\t\tlabel = sum(alphas * as.vector(Y) * (X.test[i,] %*% t(X))) + b\n",
    "\t\tif (label >= 0) \n",
    "\t\t\tlabel = 1\n",
    "\t\telse\n",
    "\t\t\tlabel = -1\n",
    "\t\texpected_label = Y.test[i,]\n",
    "\t\tall.labels = rbind(all.labels, cbind(expected_label, label))\n",
    "\t}\n",
    "\n",
    "\tcolnames(all.labels) = c(\"Expected class\", \"Predicted class\")\n",
    "\n",
    "\treturn (all.labels)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipm.svm <- function() {\n",
    "\n",
    "\t# Building up the linearly separable dataset\n",
    "\tdataset = simpleDataset()\n",
    "\n",
    "\t# Creating matrix X to represent all vector x_i (training examples)\n",
    "\tX = dataset$train[,1:2]\n",
    "\n",
    "\t# This vector y with labels -1 and +1 \n",
    "\t# (we in fact created a matrix with a single column)\n",
    "\tY = matrix(dataset$train[,3], ncol=1)\n",
    "\n",
    "\t# Number of training examples\n",
    "\tnpoints = nrow(X)\n",
    "\n",
    "\t# Computing matrix Q as we formulated\n",
    "\tQ = (Y %*% t(Y)) * (X %*% t(X))\n",
    "\n",
    "\t# Defining values to start the execution\n",
    "\tC = 1\t\t \t\t# Upper limit for alpha_i\n",
    "\teta = 0.1\t \t\t# This will be used to adapt the variables of our problem\n",
    "\tb = runif(min=-1, max=1, n=1)\t# Initial b\n",
    "\titeration = 1 \t \t\t# Counter of iteration\n",
    "\tthreshold = 1e-5 \t\t# This parameter defines the stop criterion\n",
    "\n",
    "\t# Vector filled out with ones (one's vector)\n",
    "\te = rep(1, nrow(Q))\n",
    "\n",
    "\t# Identity matrix\n",
    "\tI = diag(rep(1, nrow(Q)))\n",
    "\n",
    "\t# Setting all alphas as half of C into a diagonal matrix\n",
    "\tAlpha = diag(rep(C/2, nrow(Q)))\n",
    "\n",
    "\t# Defining the diagonal matrix Xi using the same values of alphas,\n",
    "\t# what makes constraints respected according to the values of the \n",
    "\t# slack variables \n",
    "\tXi = Alpha\n",
    "\n",
    "\t# Computing the diagonal matrix S using the first equation, as follows:\n",
    "\t# Q alpha + y b + Xi - s - e = 0\n",
    "\t# Q alpha + y b + Xi - e = s\n",
    "\tS = diag(as.vector(Q%*%diag(Alpha) + Y*b + diag(Xi) - e))\n",
    "\n",
    "\t# This value found for S helps us to compute equation:\n",
    "\t#\n",
    "\t# S alpha - mu = 0\n",
    "\t# S alpha = mu\n",
    "\t#\n",
    "\t# allowing to find the current Gap for our solution\n",
    "\t# (please refer to the first Primal-Dual Path Following algorithm\n",
    "\t#  used to tackle the linear optimization problem)\n",
    "\tgap = e%*%S%*%Alpha%*%e\n",
    "\n",
    "\t# This is the initial mu\n",
    "\tmu = as.numeric(gap)\n",
    "\n",
    "\t# Factor to reduce mu along iterations and eventually get closer to barriers.\n",
    "\t# This is necessary if the solution is close to one of the barrier terms.\n",
    "\treducing.factor = 0.9\t\t\n",
    "\n",
    "\t# Identity matrix\n",
    "\tI = diag(nrow(Q))\n",
    "\n",
    "\t# Building up the Jacobian matrix.\n",
    "\t# First and second rows will not change anymore, \n",
    "\t# therefore they are initialized before the iterative process.\n",
    "\n",
    "\t# Jacobian matrix: first row\n",
    "\tA = matrix(0, nrow=(3*npoints+1), ncol=(3*npoints+1))\n",
    "\tA[1:nrow(Q), 1:ncol(Q)] = Q\n",
    "\tA[1:nrow(Q), ncol(Q)+1] = Y\n",
    "\tA[1:nrow(Q), (ncol(Q)+2):(2*npoints+1)] = -I\n",
    "\tA[1:nrow(Q), (2*npoints+2):(3*npoints+1)] = I\n",
    "\n",
    "\t# Jacobian matrix: second row\n",
    "\tA[nrow(Q)+1, 1:length(Y)] = -t(Y)\n",
    "\n",
    "\twhile (gap > threshold) {\n",
    "\n",
    "\t\t# Jacobian matrix: third row\n",
    "\t\tA[(npoints+2):(2*npoints+1), 1:npoints] = S\n",
    "\t\tA[(npoints+2):(2*npoints+1), (npoints+2):(2*npoints+1)] = Alpha\n",
    "\n",
    "\t\t# Jacobian matrix: fourth row\n",
    "\t\tA[(2*npoints+2):(3*npoints+1), 1:npoints] = -Xi\n",
    "\t\tA[(2*npoints+2):(3*npoints+1), (2*npoints+2):(3*npoints+1)] = diag(rep(C,npoints))-Alpha\n",
    "\n",
    "\t\t# Building up vector b\n",
    "\t\tB = matrix(0, nrow=2*npoints+1, ncol=1)\n",
    "\n",
    "\t\t# First function\n",
    "\t\tf1 = - Q%*%diag(Alpha) - Y*b - diag(Xi) + diag(S) + e\n",
    "\n",
    "\t\t# Second function\n",
    "\t\tf2 = diag(Alpha)%*%Y\n",
    "\n",
    "\t\t# Third function\n",
    "\t\tf3 = -diag(S%*%Alpha) + mu\n",
    "\n",
    "\t\t# Fourth function\n",
    "\t\tf4 = -(diag(rep(C,npoints))-Alpha)%*%diag(Xi) + mu\n",
    "\n",
    "\t\tB[1:npoints] = f1\n",
    "\t\tB[npoints+1] = f2\n",
    "\t\tB[(npoints+2):(2*npoints+1)] = f3\n",
    "\t\tB[(2*npoints+2):(3*npoints+1)] = f4\n",
    "\n",
    "\t\t# Solving the system (this solver comes with the package base)\n",
    "\t\td = solve(A, B)\n",
    "\n",
    "\t\t# Cutting out the corresponding Deltas for Alpha, b, S and Xi\n",
    "\t\t# to be later used as updating factors\n",
    "\t\td_alpha = d[1:npoints]\n",
    "\t\td_b = d[npoints+1]\n",
    "\t\td_S = d[(npoints+2):(2*npoints+1)]\n",
    "\t\td_Xi = d[(2*npoints+2):(3*npoints+1)]\n",
    "\n",
    "\t\t# Updating the variables for our problem.\n",
    "\t\t# Parameter eta defines the update step\n",
    "\t\tdiag(Alpha) = diag(Alpha) + eta * d_alpha\n",
    "\t\tb = b + eta * d_b\n",
    "\t\tdiag(S) = diag(S) + eta * d_S\n",
    "\t\tdiag(Xi) = diag(Xi) + eta * d_Xi\n",
    "\n",
    "\t\t# Counting iterations\n",
    "\t\titeration = iteration + 1\n",
    "\n",
    "\t\t# Recalculating the Gap for the next iteration\n",
    "\t\tgap = e%*%S%*%Alpha%*%e\n",
    "\n",
    "\t\t# We decrease the value of mu to allow our algorithm to get\n",
    "\t\t# closer to barriers whenever necessary\n",
    "\t\tmu = mu * reducing.factor\n",
    "\n",
    "\t\tcat(\"Current Gap is \", gap, \"\\n\")\n",
    "\t}\n",
    "\n",
    "\t# Plotting the dataset and the support vectors.\n",
    "\t# Support vectors correspond to every x_i that was found to help\n",
    "\t# our algorithm define the maximal-margin hyperplane\n",
    "\tcolors = rep(1, nrow(Q))\n",
    "\tids = which(diag(Alpha) > 1e-5)\n",
    "\tcolors[ids] = 2\n",
    "\tplot(X, col=colors, main=\"Dataset and support vectors\")\n",
    "\tlocator(1)\n",
    "\n",
    "\t# Plotting the classification results.\n",
    "\t# Creating matrix X to represent all vectors x_i (test examples)\n",
    "\tX.test = dataset$test[,1:2]\n",
    "\n",
    "\t# This vector y contains labels -1 and +1\n",
    "\t# (we created a matrix with a single column)\n",
    "\tY.test = matrix(dataset$test[,3], ncol=1)\n",
    "\n",
    "\tprint(discrete.classification(X, Y, Alpha, b, X.test, Y.test, threshold = 1e-5))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipm.svm()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
